{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOQG+xcMu1Jx2v8dsE0ZwBo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g_57fu3t5-8e","executionInfo":{"status":"ok","timestamp":1748858794730,"user_tz":-330,"elapsed":2859,"user":{"displayName":"S. DANUJAN","userId":"12956502565126702793"}},"outputId":"ce957fdd-4215-486e-ce3f-a466dc56b7a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Loading attack datasets...\n","Found 1 CSV files in /content/drive/MyDrive/FYP/sampled_datasets/Testing/attack\n","Loaded /content/drive/MyDrive/FYP/sampled_datasets/Testing/attack/sampled_dataset_10000_20250602_095721.csv: 10000 rows\n","Combined /content/drive/MyDrive/FYP/sampled_datasets/Testing/attack: 10000 total rows\n","\n","Loading benign datasets...\n","Found 1 CSV files in /content/drive/MyDrive/FYP/sampled_datasets/Testing/benign\n","Loaded /content/drive/MyDrive/FYP/sampled_datasets/Testing/benign/sampled_dataset_10000_20250602_090502.csv: 10000 rows\n","Combined /content/drive/MyDrive/FYP/sampled_datasets/Testing/benign: 10000 total rows\n","\n","Randomly merging datasets...\n","Attack samples: 10000\n","Benign samples: 10000\n","Merged dataset: 20000 total rows\n","Class distribution:\n","label\n","benign    10000\n","attack    10000\n","Name: count, dtype: int64\n","\n","Saving merged dataset...\n","Merged dataset saved to: /content/drive/MyDrive/FYP/sampled_datasets/Testing/merged/randomly_merged_dataset.csv\n","File size: 20000 rows, 39 columns\n","\n","==================================================\n","MERGE COMPLETED SUCCESSFULLY!\n","==================================================\n","Attack samples: 10000\n","Benign samples: 10000\n","Total merged: 20000\n","Output file: /content/drive/MyDrive/FYP/sampled_datasets/Testing/merged/randomly_merged_dataset.csv\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import glob\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","def load_csv_files_from_folder(folder_path):\n","    \"\"\"Load all CSV files from a folder and combine them\"\"\"\n","    csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n","\n","    if not csv_files:\n","        print(f\"No CSV files found in {folder_path}\")\n","        return None\n","\n","    print(f\"Found {len(csv_files)} CSV files in {folder_path}\")\n","\n","    dataframes = []\n","    for file in csv_files:\n","        df = pd.read_csv(file)\n","        print(f\"Loaded {file}: {len(df)} rows\")\n","        dataframes.append(df)\n","\n","    # Combine all CSV files from the folder\n","    combined_df = pd.concat(dataframes, ignore_index=True)\n","    print(f\"Combined {folder_path}: {len(combined_df)} total rows\")\n","\n","    return combined_df\n","\n","def randomly_merge_datasets(attack_df, benign_df, attack_label='attack', benign_label='benign', label_column='label', random_state=42):\n","    \"\"\"Randomly merge attack and benign datasets\"\"\"\n","\n","    # Add labels\n","    attack_df = attack_df.copy()\n","    benign_df = benign_df.copy()\n","\n","    attack_df[label_column] = attack_label\n","    benign_df[label_column] = benign_label\n","\n","    print(f\"Attack samples: {len(attack_df)}\")\n","    print(f\"Benign samples: {len(benign_df)}\")\n","\n","    # Combine datasets\n","    merged_df = pd.concat([attack_df, benign_df], ignore_index=True)\n","\n","    # Randomly shuffle\n","    merged_df = merged_df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n","\n","    print(f\"Merged dataset: {len(merged_df)} total rows\")\n","    print(f\"Class distribution:\\n{merged_df[label_column].value_counts()}\")\n","\n","    return merged_df\n","\n","def save_merged_dataset(merged_df, output_folder, filename='merged_dataset.csv'):\n","    \"\"\"Save merged dataset to specified folder\"\"\"\n","\n","    # Create output directory\n","    os.makedirs(output_folder, exist_ok=True)\n","\n","    # Generate full file path\n","    output_path = os.path.join(output_folder, filename)\n","\n","    # Save dataset\n","    merged_df.to_csv(output_path, index=False)\n","\n","    print(f\"Merged dataset saved to: {output_path}\")\n","    print(f\"File size: {len(merged_df)} rows, {len(merged_df.columns)} columns\")\n","\n","    return output_path\n","\n","def main():\n","    # Define paths\n","    attack_folder = '/content/drive/MyDrive/FYP/sampled_datasets/Testing/attack'\n","    benign_folder = '/content/drive/MyDrive/FYP/sampled_datasets/Testing/benign'\n","    output_folder = '/content/drive/MyDrive/FYP/sampled_datasets/Testing/merged'\n","\n","    # Load datasets\n","    print(\"Loading attack datasets...\")\n","    attack_df = load_csv_files_from_folder(attack_folder)\n","\n","    print(\"\\nLoading benign datasets...\")\n","    benign_df = load_csv_files_from_folder(benign_folder)\n","\n","    if attack_df is None or benign_df is None:\n","        print(\"Error: Could not load datasets\")\n","        return\n","\n","    # Randomly merge datasets\n","    print(\"\\nRandomly merging datasets...\")\n","    merged_df = randomly_merge_datasets(\n","        attack_df,\n","        benign_df,\n","        attack_label='attack',\n","        benign_label='benign',\n","        label_column='label',\n","        random_state=42\n","    )\n","\n","    # Save merged dataset\n","    print(\"\\nSaving merged dataset...\")\n","    output_path = save_merged_dataset(\n","        merged_df,\n","        output_folder,\n","        'randomly_merged_dataset.csv'\n","    )\n","\n","    # Display summary\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"MERGE COMPLETED SUCCESSFULLY!\")\n","    print(\"=\"*50)\n","    print(f\"Attack samples: {len(attack_df)}\")\n","    print(f\"Benign samples: {len(benign_df)}\")\n","    print(f\"Total merged: {len(merged_df)}\")\n","    print(f\"Output file: {output_path}\")\n","\n","# Alternative function for custom paths\n","def merge_csv_custom_paths(attack_path, benign_path, output_path, filename='merged_dataset.csv'):\n","    \"\"\"Merge CSV files with custom paths\"\"\"\n","\n","    # Load datasets\n","    attack_df = load_csv_files_from_folder(attack_path)\n","    benign_df = load_csv_files_from_folder(benign_path)\n","\n","    if attack_df is None or benign_df is None:\n","        return None\n","\n","    # Merge and save\n","    merged_df = randomly_merge_datasets(attack_df, benign_df)\n","    output_file = save_merged_dataset(merged_df, output_path, filename)\n","\n","    return merged_df, output_file\n","\n","# Run the main function\n","if __name__ == \"__main__\":\n","    main()"]}]}